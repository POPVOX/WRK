# REBOOT CONGRESS 2026 - Chapter Outline

## Structure Overview

Each chapter follows a consistent format designed for multiple audiences and connected activities:

- **Executive Summary** (1 page) - For Members, busy staff, and press
- **Main Content** (8-15 pages) - Core argument with evidence
- **Technical Appendix** (as needed) - Deep dives for technologists
- **Discussion Questions** - For staff events
- **Connected Prototype** - Demo or tool where applicable

---

## Part I: The Problem

### Chapter 1: The Legislative Data Crisis
**Release: February 2026**

#### Synopsis
Congress is drowning in data while starving for information. Staff can't find what they need, when they need it, in a form they can use. This chapter quantifies the problem and establishes the stakes.

#### Learning Objectives
By the end of this chapter, readers will be able to:
1. Articulate the difference between data availability and data accessibility in Congress
2. Identify 3-5 specific data infrastructure gaps affecting legislative operations
3. Explain why current congressional data systems were designed and why they no longer meet needs
4. Connect data infrastructure gaps to specific legislative capacity problems

#### Key Content
- Staff time studies: How much time is spent finding vs. analyzing information
- Case examples: Legislation delayed or flawed due to information gaps
- Comparison: Congressional data access vs. executive branch, private sector
- The compounding problem: Each Congress starts over

#### Connected Activities
- **Prototype**: None (problem statement chapter)
- **Event tie-in**: Introduce at Q1 Staff Event (March)
- **External validation**: References to CMF studies, R Street research, etc.

#### Discussion Questions
1. What information do you need regularly that's hard to find?
2. How much of your week is spent on information retrieval vs. analysis?
3. What would you do differently if you had instant access to relevant precedents?

---

### Chapter 2: How We Got Here - The Hidden Foundation of American Law
**Release: March 2026**

#### Synopsis
The current state of legislative data infrastructure is the result of specific historical choices, not inevitable evolution. Understanding this history reveals opportunities for change.

#### Learning Objectives
By the end of this chapter, readers will be able to:
1. Trace the evolution of legislative data systems from the founding to present
2. Identify key inflection points where different choices could have been made
3. Explain why the Law Revision Counsel, GPO, and other infrastructure developed as they did
4. Recognize path dependencies that constrain current options

#### Key Content
- Pre-digital era: How Congress managed information before computers
- The 1970s modernization moment: LEGIS, SCORPIO, early databases
- The 1990s web transition: What was preserved, what was lost
- The XML era: USLM, bills in data format, Bulk Data Task Force
- What other legislatures did differently

#### Connected Activities
- **Prototype**: Historical timeline visualization
- **Event**: Q1 Staff Event (March) - "Learning from Legislative History"
- **Partners**: Engage Law Revision Counsel, GPO, CRS historians

#### Discussion Questions
1. What aspects of current systems reflect outdated assumptions?
2. Which historical decisions still constrain what's possible today?
3. What can Congress learn from how other institutions modernized?

---

## Part II: Foundations for Change

### Chapter 3: AI Fundamentals for Legislative Staff
**Release: April 2026**

#### Synopsis
A practical, non-technical introduction to AI capabilities and limitations specifically for legislative context. What can AI do, what can't it do, and what does that mean for Congress?

#### Learning Objectives
By the end of this chapter, readers will be able to:
1. Explain what large language models are and how they work (conceptually)
2. Distinguish between AI capabilities that exist today vs. speculative futures
3. Identify appropriate vs. inappropriate uses of AI in legislative context
4. Recognize common AI failure modes (hallucination, bias, brittleness)

#### Key Content
- Demystifying AI: What's actually happening when you use ChatGPT
- The capability landscape: Classification, extraction, generation, reasoning
- Failure modes: Why AI can be confidently wrong
- The human-in-the-loop imperative: Why AI can't replace judgment
- Privacy and security considerations unique to Congress

#### Connected Activities
- **Prototype**: Hands-on demo of appropriate congressional AI uses
- **Event**: Bridge chapter discussed at Q2 Staff Event
- **External**: Coordinate with AI Literacy efforts elsewhere

#### Discussion Questions
1. What tasks in your work could AI help with today?
2. What tasks should AI never do without human review?
3. How would you verify AI-generated content is accurate?

---

### Chapter 4: The Decision Trace - Capturing Institutional Knowledge
**Release: May 2026**

#### Synopsis
The fundamental innovation enabling AI-enhanced legislative operations: a structured way to capture the context, reasoning, and commitments that currently exist only in human memory.

#### Learning Objectives
By the end of this chapter, readers will be able to:
1. Explain what a "decision trace" is and why it matters
2. Identify the types of institutional knowledge currently lost between Congresses
3. Describe how captured institutional knowledge enables AI assistance
4. Evaluate the tradeoffs between comprehensive capture and operational burden

#### Key Content
- The institutional memory problem: What's lost in transitions
- Components of a decision trace: Context, options, rationale, commitments
- From note-taking to knowledge infrastructure
- Privacy-preserving approaches to institutional memory
- How the decision trace enables effective AI assistance

#### Connected Activities
- **Prototype**: Meetings Intel Tool demonstration (primary showcase)
- **Event**: Pre-Q2 event demo for interested staff
- **Partners**: Engage with offices for pilot feedback

#### Discussion Questions
1. What context do you wish previous staff had documented?
2. How would your work change if you could query past meeting commitments?
3. What information is too sensitive to capture? How would you protect what is captured?

---

### Chapter 5: Security Architecture for Congressional AI
**Release: June 2026**

#### Synopsis
A comprehensive framework for deploying AI-enabled systems in the congressional environment, meeting CAO/SAA requirements while enabling transformative capabilities.

#### Learning Objectives
By the end of this chapter, readers will be able to:
1. Identify the unique security requirements of the congressional environment
2. Explain the principles of zero-trust architecture as applied to legislative AI
3. Describe how office data sovereignty can be maintained in shared systems
4. Evaluate AI system proposals against congressional security requirements

#### Key Content
- Threat model: Who wants congressional data and why
- Security principles: Zero trust, defense in depth, privacy by design
- Office data isolation: How to collaborate without compromising sovereignty
- AI-specific security: Prompt injection, output validation, audit trails
- Compliance framework: FedRAMP, NIST, congressional-specific requirements
- Implementation roadmap: Phased approach to security

#### Connected Activities
- **Prototype**: Security demonstration of Meetings Intel Tool
- **Event**: Q2 Staff Event - "AI Security for Congressional Offices"
- **Partners**: Informal coordination with CAO/SAA

#### Discussion Questions
1. What are your office's biggest security concerns about AI tools?
2. How do you balance security with usability in your current systems?
3. What would it take for your office to trust an AI-enabled system?

---

## Part III: Transformed Operations

### Chapter 6: Constituent Services Transformed
**Release: July 2026**

#### Synopsis
How AI-enabled systems could transform constituent casework—reducing response times, preventing cases from falling through cracks, and enabling proactive service while protecting privacy.

#### Learning Objectives
By the end of this chapter, readers will be able to:
1. Identify pain points in current constituent casework processes
2. Describe how AI could assist casework without replacing caseworkers
3. Explain privacy-preserving approaches to case management
4. Evaluate when technology helps vs. when human connection is essential

#### Key Content
- Current state: How casework works (and doesn't work) today
- The AI-assisted caseworker: What augmentation looks like
- Privacy-first design: Protecting constituent data absolutely
- Pattern detection: Identifying systemic issues before they escalate
- Measuring success: Constituent outcomes, not just case volume

#### Connected Activities
- **Prototype**: Casework module design showcase
- **Event**: Discussed at Q3 Staff Event
- **Partners**: Engage constituent service organizations, CMF

#### Discussion Questions
1. What's the biggest time sink in your casework process?
2. How do you currently identify patterns across constituent contacts?
3. What would you never want a machine to do in casework?

---

### Chapter 7: Cross-Office Coordination
**Release: August 2026**

#### Synopsis
How AI agents could enable new forms of coordination across congressional offices—state delegations, committee members, issue coalitions—while maintaining office autonomy.

#### Learning Objectives
By the end of this chapter, readers will be able to:
1. Identify current barriers to effective cross-office coordination
2. Describe the "virtual collaboration space" concept
3. Explain how consent-based data sharing enables coordination without surveillance
4. Evaluate coordination opportunities relevant to their work

#### Key Content
- The coordination gap: Why offices are silos
- Virtual collaboration spaces: How agents can coordinate
- Consent architecture: Only share what you choose
- Use cases: State delegations, issue coalitions, committee coordination
- Governance: Rules for shared spaces

#### Connected Activities
- **Prototype**: Multi-office coordination demo
- **Event**: Preparation for Q3 Staff Event feature
- **Partners**: Engage state delegation staff groups

#### Discussion Questions
1. When has cross-office coordination worked well? What made it work?
2. What would you share with your delegation that you wouldn't share publicly?
3. How should shared spaces be governed?

---

### Chapter 8: Case Study - Disaster Response Coordination
**Release: September 2026**

#### Synopsis
A detailed case study demonstrating how the concepts from previous chapters come together in a high-stakes scenario: coordinating congressional disaster response.

#### Learning Objectives
By the end of this chapter, readers will be able to:
1. Visualize how AI-enabled coordination works in practice
2. Identify the components (decision trace, virtual spaces, agency integration) working together
3. Compare current disaster response coordination to the envisioned future
4. Apply the framework to other coordination challenges

#### Key Content
- The scenario: Major disaster affecting multiple districts
- Current reality: How coordination works (and fails) today
- The alternative: AI-enabled coordination in action
- Detailed walkthrough: Day-by-day comparison
- Underlying architecture: What makes it possible
- Path to reality: What would need to happen

#### Connected Activities
- **Prototype**: Disaster response simulation or demo
- **Event**: Q3 Staff Event - "AI for Congressional Coordination"
- **Partners**: Engage former disaster response coordinators, FEMA liaisons

#### Discussion Questions
1. What coordination challenges do you face that are similar to disaster response?
2. What would need to be true for your office to participate in such a system?
3. How should constituent privacy be balanced with coordination needs in emergencies?

---

## Part IV: Integration and Oversight

### Chapter 9: Agency Integration and Congressional Oversight
**Release: October 2026**

#### Synopsis
How AI-enabled systems could transform Congress's relationship with executive agencies—making oversight more effective, casework more efficient, and information flows more reliable.

#### Learning Objectives
By the end of this chapter, readers will be able to:
1. Identify current breakdowns in Congress-agency information flows
2. Describe how AI liaison agents could improve agency integration
3. Explain oversight implications of agency AI adoption
4. Evaluate proposals for improved Congress-agency data exchange

#### Key Content
- The oversight gap: What Congress doesn't know about agency AI
- Current casework friction: Inquiries, responses, lost context
- AI liaison architecture: How agents could coordinate across branches
- Oversight requirements: What Congress should demand from agency AI
- The appropriations lever: Using funding to drive transparency

#### Connected Activities
- **Prototype**: Agency integration prototype (if available)
- **Event**: Stakeholder review discussions
- **Partners**: Engage GAO, former appropriators, agency liaisons

#### Discussion Questions
1. What agency information is hardest to get when you need it?
2. How should Congress oversee AI systems it doesn't fully understand?
3. What data should agencies be required to provide about their AI systems?

---

### Chapter 10: Governance Framework for Congressional AI
**Release: November 2026**

#### Synopsis
Who decides what AI systems Congress uses, how they're governed, and how they're held accountable? A framework for institutional AI governance.

#### Learning Objectives
By the end of this chapter, readers will be able to:
1. Identify governance gaps in current congressional technology adoption
2. Describe a governance framework for AI-enabled legislative systems
3. Explain the roles of CAO, SAA, committees, and individual offices
4. Evaluate AI proposals against good governance principles

#### Key Content
- Current governance: How technology decisions are made (and not made)
- A governance framework: Principles, bodies, processes
- Member sovereignty: Protecting office autonomy
- Transparency requirements: What should be public about congressional AI
- Continuous improvement: Learning from use

#### Connected Activities
- **Prototype**: Governance dashboard concept
- **Event**: Stakeholder review with governance focus
- **Partners**: House Administration, Senate Rules, CAO, SAA

#### Discussion Questions
1. Who should decide what AI tools your office can use?
2. What transparency should exist about congressional AI use?
3. How can governance be both protective and enabling?

---

## Part V: Recommendations

### Chapter 11: Final Report - Recommendations for the 120th Congress
**Release: December 2026**

#### Synopsis
The culmination of the year's work: specific, actionable recommendations for rules changes, appropriations, committee capacity, new tools, and governance frameworks.

#### Learning Objectives
By the end of this chapter, readers will be able to:
1. Articulate a comprehensive vision for congressional AI adoption
2. Identify specific rules changes needed in House and Senate
3. Describe appropriations priorities for congressional capacity
4. Explain committee-level changes that would improve oversight
5. Advocate for recommendations with specific talking points

#### Key Content

**SECTION 1: Rules Recommendations**
- House Rules changes for the 120th Congress
- Senate Rules recommendations
- Committee rules modernization
- Joint rules considerations

**SECTION 2: Appropriations Recommendations**
- Legislative branch appropriations priorities
- Capacity investments needed
- Multi-year funding strategies
- Metrics for success

**SECTION 3: Committee Capacity**
- Expertise requirements for AI oversight
- Shared staff resources
- Training and development
- External expert access

**SECTION 4: Infrastructure and Tools**
- Data infrastructure priorities
- Tool development roadmap
- Adoption strategy
- Interoperability requirements

**SECTION 5: Governance and Oversight**
- Internal governance framework
- Executive branch oversight requirements
- Transparency and accountability mechanisms
- Continuous improvement processes

#### Connected Activities
- **Event**: Q4 Launch Event - Release of final recommendations
- **Deliverable**: One-page summary for press
- **Deliverable**: Detailed implementation appendix
- **Partners**: All partners for endorsement

---

## Technical Appendices

### Appendix A: Data Models and Schemas
Detailed technical specifications for decision trace, collaboration spaces, and agency integration.

### Appendix B: Security Control Mapping
NIST 800-53 control mapping for congressional AI systems.

### Appendix C: Implementation Roadmaps
Phased implementation plans for each major recommendation.

### Appendix D: Prototype Documentation
Technical documentation for all demonstrated prototypes.

### Appendix E: Glossary
Terms and definitions for non-technical readers.

---

## Cross-Cutting Themes

These themes should appear consistently across all chapters:

1. **Bipartisan Implementation**: Every recommendation works regardless of majority control
2. **Human Authority**: AI assists; humans decide
3. **Privacy by Design**: Constituent and deliberative protection is non-negotiable
4. **Practical Over Theoretical**: Real examples, working prototypes
5. **Building on Existing Work**: Credit and extend prior modernization efforts
6. **The 120th Moment**: Connect everything to January 2027 opportunity

---

*Last updated: December 2025*
